{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0597206-0df4-4ab8-a595-b74fd164a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler,\n",
    "                                   QuantileTransformer, StandardScaler)\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84596c34-8fd6-4e8f-b865-4fe8216d4bb6",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0cde000-430b-4996-a803-7b691706eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_loc_time(data_path: str, output_path: str) -> None:\n",
    "    \"\"\"Sort data by location and time and save to a parquet file.\"\"\"\n",
    "    df = pd.read_parquet(data_path)\n",
    "    df = df.sort_values(['location', 'time'])\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852c4ce-71e6-4a81-a872-e3cfd40b4816",
   "metadata": {},
   "source": [
    "# processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0250c6-523f-4f4d-9036-6524e3f5fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tft_process(path: str, hist_len: int, fut_len: int, output_path: str) -> None:\n",
    "    \"\"\"Create TFT training data from a sorted parquet file.\"\"\"\n",
    "    output_filename = Path(path).with_suffix('.pkl').name\n",
    "\n",
    "    df = pd.read_parquet(path)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    # Extract day of year\n",
    "    df['doy'] = df['time'].dt.dayofyear\n",
    "\n",
    "    df = df[['time', 'location', 'latitude', 'longitude', 'tmin', 'tmax',\n",
    "             'precipitation', 'radiation', 'photoperiod', 'swvl1',\n",
    "             'sif_clear_inst']]\n",
    "    df = df.dropna()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    meta_attrs = ['time', 'location']\n",
    "    known_attrs = ['tmin', 'tmax', 'radiation', 'precipitation', 'swvl1', 'photoperiod', 'doy']\n",
    "    static_attrs = ['latitude', 'longitude']\n",
    "    categorical_attrs = []\n",
    "\n",
    "    all_cols = list(df.columns)\n",
    "    feature_cols = [c for c in all_cols if c not in meta_attrs]\n",
    "\n",
    "    feature_map = {\n",
    "        'static_feats_numeric': [c for c in feature_cols if c in static_attrs and c not in categorical_attrs],\n",
    "        'static_feats_categorical': [c for c in feature_cols if c in static_attrs and c in categorical_attrs],\n",
    "        'historical_ts_numeric': [c for c in feature_cols if c not in static_attrs and c not in categorical_attrs],\n",
    "        'historical_ts_categorical': [c for c in feature_cols if c not in static_attrs and c in categorical_attrs],\n",
    "        'future_ts_numeric': [c for c in feature_cols if c in known_attrs and c not in categorical_attrs],\n",
    "        'future_ts_categorical': [c for c in feature_cols if c in known_attrs and c in categorical_attrs],\n",
    "    }\n",
    "\n",
    "    scalers = {'numeric': {}, 'categorical': {}}\n",
    "    categorical_cardinalities = {}\n",
    "\n",
    "    for col in tqdm(feature_cols, desc=\"fit_scalers\"):\n",
    "        if col in categorical_attrs:\n",
    "            enc = LabelEncoder().fit(df[col].values)\n",
    "            scalers['categorical'][col] = enc\n",
    "            categorical_cardinalities[col] = df[col].nunique()\n",
    "        else:\n",
    "            if col == 'sif_clear_inst':\n",
    "                scaler = StandardScaler()\n",
    "            elif col == 'day_of_year':\n",
    "                scaler = MinMaxScaler()\n",
    "            else:\n",
    "                scaler = QuantileTransformer(n_quantiles=256)\n",
    "            scalers['numeric'][col] = scaler.fit(df[col].astype(float).values.reshape(-1, 1))\n",
    "\n",
    "    for col in tqdm(feature_cols, desc=\"transform\"): \n",
    "        if col in categorical_attrs:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        else:\n",
    "            df[col] = scalers['numeric'][col].transform(df[col].values.reshape(-1, 1)).squeeze().astype(np.float32)\n",
    "\n",
    "    train_subset = df[(df['time'] >= datetime(1982, 1, 1)) &\n",
    "                      (df['time'] < datetime(2012, 1, 1))]\n",
    "    \n",
    "    val_subset   = df[(df['time'] >= datetime(2012, 1, 1)) &\n",
    "                      (df['time'] < datetime(2017, 1, 1))]\n",
    "    \n",
    "    test_subset  = df[(df['time'] >= datetime(2017, 1, 1)) &\n",
    "                      (df['time'] < datetime(2022, 1, 1))]\n",
    "    \n",
    "    subsets = {'train': train_subset,\n",
    "               'validation': val_subset,\n",
    "               'test': test_subset}\n",
    "\n",
    "    data_sets = {k: {} for k in ['train', 'validation', 'test']}\n",
    "    for subset in subsets.values():\n",
    "        subset['id'] = subset['location'].astype(str) + '_' + subset['time'].astype(str)\n",
    "\n",
    "    for subset_key, subset_data in subsets.items():\n",
    "        samp_interval = hist_len + fut_len\n",
    "        for i in range(0, len(subset_data), samp_interval):\n",
    "            slc = subset_data.iloc[i:i + samp_interval]\n",
    "            if len(slc) < samp_interval or slc.iloc[0]['location'] != slc.iloc[-1]['location']:\n",
    "                continue\n",
    "            data_sets[subset_key].setdefault('time_index', []).append(slc.iloc[hist_len - 1]['location'])\n",
    "            data_sets[subset_key].setdefault('static_feats_numeric', []).append(\n",
    "                slc.iloc[0][feature_map['static_feats_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('static_feats_categorical', []).append(\n",
    "                slc.iloc[0][feature_map['static_feats_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('historical_ts_numeric', []).append(\n",
    "                slc.iloc[:hist_len][feature_map['historical_ts_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('historical_ts_categorical', []).append(\n",
    "                slc.iloc[:hist_len][feature_map['historical_ts_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('future_ts_numeric', []).append(\n",
    "                slc.iloc[hist_len:][feature_map['future_ts_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('future_ts_categorical', []).append(\n",
    "                slc.iloc[hist_len:][feature_map['future_ts_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('target', []).append(\n",
    "                slc.iloc[hist_len:]['sif_clear_inst'].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('id', []).append(\n",
    "                slc.iloc[hist_len:]['id'].values.astype(str))\n",
    "\n",
    "    for set_key, comps in data_sets.items():\n",
    "        for arr_key, arr in comps.items():\n",
    "            data_sets[set_key][arr_key] = np.array(arr)\n",
    "\n",
    "    output_dir = Path(output_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_dir / output_filename, 'wb') as f:\n",
    "        pickle.dump({'data_sets': data_sets,\n",
    "                     'feature_map': feature_map,\n",
    "                     'scalers': scalers,\n",
    "                     'categorical_cardinalities': categorical_cardinalities}, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2e2487-3dff-4610-98c8-0f24087e60e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1e01d1e92449a4b670bb3fd75b7234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fit_scalers:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c12a7fc3ba460aadfc1ea4c3c311fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transform:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_772/2044835462.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['id'] = subset['location'].astype(str) + '_' + subset['time'].astype(str)\n",
      "/tmp/ipykernel_772/2044835462.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['id'] = subset['location'].astype(str) + '_' + subset['time'].astype(str)\n",
      "/tmp/ipykernel_772/2044835462.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['id'] = subset['location'].astype(str) + '_' + subset['time'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "path= '/home/jovyan/research_code/Transformers/temportal_fusion_transformers/data/CSIFMETEO/BDT_50_20/sorted_BDT_50_20_merged_1982_2021_US_MMS.parquet'\n",
    "hist_len = 60\n",
    "fut_len = 10\n",
    "output_path = '/home/jovyan/phenology-ml-clm/data/'\n",
    "tft_process(path, hist_len, fut_len, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654d3593-421e-4862-b234-c33fa6499c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_BDT_50_20_merged_1982_2021_US_MMS.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f491470-aad2-42d1-ad07-110cc43363fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/phenology-ml-clm/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbb398f-c942-4c14-9e06-7150215714e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>sif_clear_inst</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>radiation</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>soil</th>\n",
       "      <th>photoperiod</th>\n",
       "      <th>swvl1</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982-01-15</td>\n",
       "      <td>13243</td>\n",
       "      <td>0.106985</td>\n",
       "      <td>247.8750</td>\n",
       "      <td>271.5625</td>\n",
       "      <td>7538240.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>39.50</td>\n",
       "      <td>-86.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.504436</td>\n",
       "      <td>-1.320243e-05</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982-01-16</td>\n",
       "      <td>13243</td>\n",
       "      <td>0.105275</td>\n",
       "      <td>248.4375</td>\n",
       "      <td>273.1875</td>\n",
       "      <td>11439232.0</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>39.50</td>\n",
       "      <td>-86.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.527534</td>\n",
       "      <td>-1.043081e-06</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982-01-17</td>\n",
       "      <td>13243</td>\n",
       "      <td>0.103565</td>\n",
       "      <td>240.5000</td>\n",
       "      <td>256.9375</td>\n",
       "      <td>6629952.0</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>39.50</td>\n",
       "      <td>-86.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.551383</td>\n",
       "      <td>-1.043081e-06</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-01-18</td>\n",
       "      <td>13243</td>\n",
       "      <td>0.101855</td>\n",
       "      <td>257.0000</td>\n",
       "      <td>270.3750</td>\n",
       "      <td>8585728.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>-86.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.575972</td>\n",
       "      <td>-1.043081e-06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982-01-19</td>\n",
       "      <td>13243</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>263.9375</td>\n",
       "      <td>274.2500</td>\n",
       "      <td>2473216.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>39.50</td>\n",
       "      <td>-86.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.601283</td>\n",
       "      <td>1.111627e-05</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58379</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>13437</td>\n",
       "      <td>0.077710</td>\n",
       "      <td>280.7500</td>\n",
       "      <td>292.2500</td>\n",
       "      <td>3886656.0</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-86.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.251109</td>\n",
       "      <td>-1.233816e-05</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58380</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>13437</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>278.5000</td>\n",
       "      <td>286.8750</td>\n",
       "      <td>1294464.0</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-86.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.257565</td>\n",
       "      <td>-5.960464e-08</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58381</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>13437</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>278.6250</td>\n",
       "      <td>282.0000</td>\n",
       "      <td>3664384.0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-86.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.264963</td>\n",
       "      <td>1.221895e-05</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58382</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>13437</td>\n",
       "      <td>0.077249</td>\n",
       "      <td>277.6875</td>\n",
       "      <td>282.9375</td>\n",
       "      <td>3648448.0</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-86.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.273299</td>\n",
       "      <td>1.221895e-05</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58383</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>13437</td>\n",
       "      <td>0.077096</td>\n",
       "      <td>278.8750</td>\n",
       "      <td>287.7500</td>\n",
       "      <td>5152960.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-86.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.282566</td>\n",
       "      <td>-5.960464e-08</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58384 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  location  sif_clear_inst      tmin      tmax   radiation  \\\n",
       "0     1982-01-15     13243        0.106985  247.8750  271.5625   7538240.0   \n",
       "1     1982-01-16     13243        0.105275  248.4375  273.1875  11439232.0   \n",
       "2     1982-01-17     13243        0.103565  240.5000  256.9375   6629952.0   \n",
       "3     1982-01-18     13243        0.101855  257.0000  270.3750   8585728.0   \n",
       "4     1982-01-19     13243        0.100145  263.9375  274.2500   2473216.0   \n",
       "...          ...       ...             ...       ...       ...         ...   \n",
       "58379 2021-12-27     13437        0.077710  280.7500  292.2500   3886656.0   \n",
       "58380 2021-12-28     13437        0.077557  278.5000  286.8750   1294464.0   \n",
       "58381 2021-12-29     13437        0.077403  278.6250  282.0000   3664384.0   \n",
       "58382 2021-12-30     13437        0.077249  277.6875  282.9375   3648448.0   \n",
       "58383 2021-12-31     13437        0.077096  278.8750  287.7500   5152960.0   \n",
       "\n",
       "       precipitation  latitude  longitude  soil  photoperiod         swvl1  \\\n",
       "0           0.000977     39.50     -86.50   4.0     9.504436 -1.320243e-05   \n",
       "1           0.004761     39.50     -86.50   4.0     9.527534 -1.043081e-06   \n",
       "2           0.000916     39.50     -86.50   4.0     9.551383 -1.043081e-06   \n",
       "3           0.000000     39.50     -86.50   4.0     9.575972 -1.043081e-06   \n",
       "4           0.000122     39.50     -86.50   4.0     9.601283  1.111627e-05   \n",
       "...              ...       ...        ...   ...          ...           ...   \n",
       "58379       0.003540     39.25     -86.25   4.0     9.251109 -1.233816e-05   \n",
       "58380       0.016479     39.25     -86.25   4.0     9.257565 -5.960464e-08   \n",
       "58381       0.000488     39.25     -86.25   4.0     9.264963  1.221895e-05   \n",
       "58382       0.002014     39.25     -86.25   4.0     9.273299  1.221895e-05   \n",
       "58383       0.000000     39.25     -86.25   4.0     9.282566 -5.960464e-08   \n",
       "\n",
       "       doy  \n",
       "0       15  \n",
       "1       16  \n",
       "2       17  \n",
       "3       18  \n",
       "4       19  \n",
       "...    ...  \n",
       "58379  361  \n",
       "58380  362  \n",
       "58381  363  \n",
       "58382  364  \n",
       "58383  365  \n",
       "\n",
       "[58384 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= '/home/jovyan/research_code/Transformers/temportal_fusion_transformers/data/CSIFMETEO/BDT_50_20/sorted_BDT_50_20_merged_1982_2021_US_MMS.parquet'\n",
    "\n",
    "df = pd.read_parquet(path)\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Extract day of year\n",
    "df['doy'] = df['time'].dt.dayofyear\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90baee-4ac6-4dd1-919f-6bdffdb6d786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
