{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0597206-0df4-4ab8-a595-b74fd164a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler,\n",
    "                                   QuantileTransformer, StandardScaler)\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84596c34-8fd6-4e8f-b865-4fe8216d4bb6",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cde000-430b-4996-a803-7b691706eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_loc_time(data_path: str, output_path: str) -> None:\n",
    "    \"\"\"Sort data by location and time and save to a parquet file.\"\"\"\n",
    "    df = pd.read_parquet(data_path)\n",
    "    df = df.sort_values(['location', 'time'])\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852c4ce-71e6-4a81-a872-e3cfd40b4816",
   "metadata": {},
   "source": [
    "# processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0250c6-523f-4f4d-9036-6524e3f5fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tft_process(path: str, hist_len: int, fut_len: int, output_path: str) -> None:\n",
    "    \"\"\"Create TFT training data from a sorted parquet file.\"\"\"\n",
    "    output_filename = Path(path).with_suffix('.pkl').name\n",
    "\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df[['time', 'location', 'latitude', 'longitude', 'tmin', 'tmax',\n",
    "             'precipitation', 'radiation', 'photoperiod', 'swvl1',\n",
    "             'sif_clear_inst']]\n",
    "    df = df.dropna()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    meta_attrs = ['time', 'location']\n",
    "    known_attrs = ['tmin', 'tmax', 'radiation', 'precipitation', 'swvl1', 'photoperiod']\n",
    "    static_attrs = ['latitude', 'longitude']\n",
    "    categorical_attrs = []\n",
    "\n",
    "    all_cols = list(df.columns)\n",
    "    feature_cols = [c for c in all_cols if c not in meta_attrs]\n",
    "\n",
    "    feature_map = {\n",
    "        'static_feats_numeric': [c for c in feature_cols if c in static_attrs and c not in categorical_attrs],\n",
    "        'static_feats_categorical': [c for c in feature_cols if c in static_attrs and c in categorical_attrs],\n",
    "        'historical_ts_numeric': [c for c in feature_cols if c not in static_attrs and c not in categorical_attrs],\n",
    "        'historical_ts_categorical': [c for c in feature_cols if c not in static_attrs and c in categorical_attrs],\n",
    "        'future_ts_numeric': [],\n",
    "        'future_ts_categorical': [],\n",
    "    }\n",
    "\n",
    "    scalers = {'numeric': {}, 'categorical': {}}\n",
    "    categorical_cardinalities = {}\n",
    "\n",
    "    for col in tqdm(feature_cols, desc=\"fit_scalers\"):\n",
    "        if col in categorical_attrs:\n",
    "            enc = LabelEncoder().fit(df[col].values)\n",
    "            scalers['categorical'][col] = enc\n",
    "            categorical_cardinalities[col] = df[col].nunique()\n",
    "        else:\n",
    "            if col == 'sif_clear_inst':\n",
    "                scaler = StandardScaler()\n",
    "            elif col == 'day_of_year':\n",
    "                scaler = MinMaxScaler()\n",
    "            else:\n",
    "                scaler = QuantileTransformer(n_quantiles=256)\n",
    "            scalers['numeric'][col] = scaler.fit(df[col].astype(float).values.reshape(-1, 1))\n",
    "\n",
    "    for col in tqdm(feature_cols, desc=\"transform\"): \n",
    "        if col in categorical_attrs:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        else:\n",
    "            df[col] = scalers['numeric'][col].transform(df[col].values.reshape(-1, 1)).squeeze().astype(np.float32)\n",
    "\n",
    "    train_subset = df[(df['time'] >= datetime(1982, 1, 1)) &\n",
    "                      (df['time'] < datetime(2012, 1, 1))]\n",
    "    \n",
    "    val_subset   = df[(df['time'] >= datetime(2012, 1, 1)) &\n",
    "                      (df['time'] < datetime(2017, 1, 1))]\n",
    "    \n",
    "    test_subset  = df[(df['time'] >= datetime(2017, 1, 1)) &\n",
    "                      (df['time'] < datetime(2022, 1, 1))]\n",
    "    \n",
    "    subsets = {'train': train_subset,\n",
    "               'validation': val_subset,\n",
    "               'test': test_subset}\n",
    "\n",
    "    data_sets = {k: {} for k in ['train', 'validation', 'test']}\n",
    "    for subset in subsets.values():\n",
    "        subset['id'] = subset['location'].astype(str) + '_' + subset['time'].astype(str)\n",
    "\n",
    "    for subset_key, subset_data in subsets.items():\n",
    "        samp_interval = hist_len + fut_len\n",
    "        for i in range(0, len(subset_data), samp_interval):\n",
    "            slc = subset_data.iloc[i:i + samp_interval]\n",
    "            if len(slc) < samp_interval or slc.iloc[0]['location'] != slc.iloc[-1]['location']:\n",
    "                continue\n",
    "            data_sets[subset_key].setdefault('time_index', []).append(slc.iloc[hist_len - 1]['location'])\n",
    "            data_sets[subset_key].setdefault('static_feats_numeric', []).append(\n",
    "                slc.iloc[0][feature_map['static_feats_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('static_feats_categorical', []).append(\n",
    "                slc.iloc[0][feature_map['static_feats_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('historical_ts_numeric', []).append(\n",
    "                slc.iloc[:hist_len][feature_map['historical_ts_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('historical_ts_categorical', []).append(\n",
    "                slc.iloc[:hist_len][feature_map['historical_ts_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('future_ts_numeric', []).append(\n",
    "                slc.iloc[hist_len:][feature_map['future_ts_numeric']].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('future_ts_categorical', []).append(\n",
    "                slc.iloc[hist_len:][feature_map['future_ts_categorical']].values.astype(np.int32))\n",
    "            data_sets[subset_key].setdefault('target', []).append(\n",
    "                slc.iloc[hist_len:]['sif_clear_inst'].values.astype(np.float32))\n",
    "            data_sets[subset_key].setdefault('id', []).append(\n",
    "                slc.iloc[hist_len:]['id'].values.astype(str))\n",
    "\n",
    "    for set_key, comps in data_sets.items():\n",
    "        for arr_key, arr in comps.items():\n",
    "            data_sets[set_key][arr_key] = np.array(arr)\n",
    "\n",
    "    output_dir = Path(output_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_dir / output_filename, 'wb') as f:\n",
    "        pickle.dump({'data_sets': data_sets,\n",
    "                     'feature_map': feature_map,\n",
    "                     'scalers': scalers,\n",
    "                     'categorical_cardinalities': categorical_cardinalities}, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e2487-3dff-4610-98c8-0f24087e60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/burg/glab/users/al4385/data/CSIFMETEO/sorted_merged_BDT_1982_2021.parquet'\n",
    "hist_len = 60\n",
    "fut_len = 10\n",
    "output_path = '/burg/glab/users/al4385/data/CLM_ml_phenology/'\n",
    "tft_process(path, hist_len, fut_len, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d3593-421e-4862-b234-c33fa6499c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
